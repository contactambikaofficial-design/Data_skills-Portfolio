- **Author:** Ambika Gokul  
- **Bootcamp Duration:** 8 Weeks  
- **Specialization:** Data Analysis

# Data Technician Bootcamp – 8 Week Learning Journey
##  Overview

This repository contains projects, exercises, and notes from my 8-week Data Technician Bootcamp. 
The bootcamp focused on building practical data analytics and technical skills — including data cleaning, visualization, SQL querying,Azure cloud and automation using Python.
Each week introduced new tools and hands-on assignments designed to simulate real-world data analysis tasks.
The bootcamp emphasized the analysis of various datasets, including global GDP performance, to derive meaningful data-driven insights.

## Bootcamp Structure
**Duration:** 8 Weeks  
**Focus Areas:**
### Week 1 – Data Fundamentals and Excel for Analysis
Learned the basics of data handling and organization using Microsoft Excel.  
Focused on functions, pivot tables, and basic statistical analysis to summarize and interpret datasets efficiently.
###  Week 2 – Data Visualization using Power BI / Tableau
Explored techniques for visualizing data insights through interactive dashboards.  
Gained experience in connecting data sources, creating charts, and designing reports to communicate business trends effectively.
###  Week 3 – SQL for Data Extraction and Querying
Developed skills to extract, filter, and aggregate data using SQL queries.  
Worked with relational databases to understand joins, subqueries, and data normalization principles.
###  Week 5 – Azure Cloud for Data Analysis
Introduced to cloud-based data services on Microsoft Azure and explored relational, non-relational, and analytical data using Azure services. 
Learned how to store, process, and analyze data using Azure SQL, Data Factory, Data Lake, and Synapse.
Integrated Power BI with Azure SQL to visualise KPIs such as daily sales, top products, and customer loyalty trends.
###  Week 6 – Python for Data Analysis (pandas, NumPy, Matplotlib,Seaborn)
Used Python to clean, analyze, and visualize data programmatically.  
Practiced using pandas for data manipulation, NumPy for computations, and Matplotlib for visual representation of trends and patterns.

##  Tools & Technologies
**Programming**:Python, SQL  
**Libraries**: pandas, matplotlib, seaborn  
**Visualization**: Power BI / Tableau  
**Version Control**: Git & GitHub  
**Data Sources**:CSV, Excel, and SQL databases  
**Cloud**:Azure SQL Database ,Azure Data Lake

##  Key Learnings
- How to structure and document data analysis workflows  
- Writing efficient SQL queries for data extraction  
- Cleaning and transforming raw data for insights  
- Building dashboards to communicate findings  
- Using GitHub for version control and collaboration

 ##  Key Projects
### **Spotify and Retail Dashboard**
- Created interactive **Tableau** and **Power BI** dashboards.
### **Paws and Whiskers – Azure Cloud**
- Integrated **SQL**, **Azure Data Lake**, and **Power BI** dashboards for real-time reporting under **GDPR compliance**.
### **GDP per Capita Analysis**
- Used **Python**, **Pandas**, and **Matplotlib** to clean and visualize data, trends through charts .

 ##  Week 1 – Data Fundamentals and Excel for Analysis


###  Overview
This week focused on building a strong foundation in **data handling, organization, and basic analysis** using **Microsoft Excel** — one of the most essential tools for any data professional.

###  Key Learnings
- Understanding **data types**, **formats**, and **data organization principles**  
- Using **Excel formulas and functions** for data manipulation (e.g., `VLOOKUP`, `IF`, `SUMIFS`, `AVERAGE`)  
- Creating **Pivot Tables** to summarize large datasets and identify trends  
- Applying **basic statistical analysis** (mean, median, standard deviation) for data insights  
- Using **conditional formatting** and **charts** to visualize patterns and relationships  
- Cleaning messy data using tools like **Text to Columns**, **Remove Duplicates**, and **Data Validation**

###  Practical Exercise
- Analyzed a **sales dataset** to calculate regional performance and monthly growth rates  
- Built an **interactive dashboard** using Pivot Charts and slicers to visualize key metrics

###  Tools & Skills
- **Microsoft Excel**  
- **Data Cleaning**  
- **Pivot Tables & Charts**  
- **Descriptive Statistics**

  
###   Pivot Table in Excel
![Product Revenue Excel](Images/Product%20Revenue%20-Pivot%20Table%20in%20Excel.jpg)

By the end of Week 1, I was able to transform raw datasets into clean, structured information and generate clear, data-driven insights using Excel.


---
##  Week 2 – Data Visualization using Power BI / Tableau

###  Overview
This week focused on learning how to transform raw data into meaningful and interactive visual insights using **Power BI** and **Tableau**.  
The goal was to understand how to design dashboards that effectively communicate business performance and analytical stories.



###  Key Learnings
- Connected **multiple data sources** (Excel, CSV, SQL) into Power BI and Tableau  
- Designed **interactive dashboards** with slicers, filters, and drill-through options  
- Created **KPIs and measures** using DAX in Power BI  
- Learned **chart selection principles** — when to use bar charts, pie charts, heat maps, and line charts  
- Explored **data modeling concepts** like relationships, hierarchies, and calculated fields  
- Focused on **design aesthetics** (color consistency, layout balance, and readability)



###  Practical Exercise
- Built a **Shopping Data Dashboard** and **Sales Analysis Dashboard** using Tableau and Power BI to analyze sales trends, customer demographics, and product category performance.  
- Added interactive filters to allow users to explore data by region and time period  
- Published the dashboard and shared insights.
   



###  Tools & Skills
- **Power BI** and **Tableau** for visualization  
- **DAX (Data Analysis Expressions)** for custom calculations  
- **Data Modeling** and **Dashboard Design**  
- **Storytelling with Data**



###  Tableau and Power BI dashboard
![Shopping Data Dashboard](Images/Shopping%20Data%20Dashboard%20using%20Tableau.jpg)
![Sales Dashboard](Images/Sales,Profit%20Margin-Power%20BI.jpg)



 By the end of Week 2, I was able to build fully interactive, professional-grade dashboards that transformed datasets into actionable business insights.


---
##  Week 3 – SQL for Data Extraction and Querying

###  Overview
This week focused on mastering **Structured Query Language (SQL)** — the foundation for working with relational databases.  
The primary goal was to learn how to **extract, filter, and manipulate data** efficiently to support data-driven decision-making.



###  Key Learnings
- Understood **database concepts** such as tables, relationships, and primary/foreign keys  
- Performed **data extraction** using `SELECT`, `WHERE`, and `ORDER BY` statements  
- Used **aggregate functions** like `SUM()`, `COUNT()`, `AVG()`, and `GROUP BY` to summarize datasets  
- Combined multiple tables using **JOINs** (`INNER JOIN`, `LEFT JOIN`, `RIGHT JOIN`, `FULL JOIN`)  
- Practiced writing **subqueries** to handle complex analytical questions  
- Learned **data normalization** principles to reduce redundancy and improve database design  
- Applied **filtering and sorting techniques** to extract relevant business insights  



###  Practical Exercise
- Queried a **retail sales database** to calculate total revenue, customer purchase frequency, and top-selling products  
- Used **JOINs and subqueries** to combine sales, customer, and product data for deeper analysis  



###  Tools & Skills
- **SQL** (Structured Query Language)  
- **MySQL / SQL Server**  
- **Joins, Aggregations, Subqueries**  
- **Database Normalization**


###  SQL
![SQL Join](Images/SQL%20using%20Inner%20Join.jpg)


By the end of Week 3, I was able to write optimized SQL queries to extract actionable insights from relational databases and prepare clean datasets for analysis.

---

##  Week 5 – Azure Cloud for Data Analysis

###  Overview
This week focused on understanding how to perform **data analysis in the cloud** using **Microsoft Azure**.  
The main objective was to explore how cloud platforms handle **data storage, processing, integration, and visualization** at scale.


###  Key Learnings
- Gained an understanding of **Azure architecture** and its key components for data analysis  
- Worked with **Azure SQL Database** to manage and query relational data in the cloud  
- Used **Azure Data Factory** to automate data movement and transformation pipelines  
- Explored **Azure Data Lake** for storing and accessing large volumes of structured and unstructured data  
- Learned to use **Azure Synapse Analytics** for integrating and analyzing data from multiple sources  
- Connected **Power BI** to Azure SQL Database to visualize key metrics and create cloud-based dashboards


###  Practical Exercise
- Designed a cloud-based data pipeline to load and process sales and customer data  
- Used **Azure Data Factory** to extract data from multiple sources and load it into **Azure SQL Database**  
- Built a **Power BI dashboard** connected to Azure SQL to visualize KPIs such as:
  - Daily Sales  
  - Top-Selling Products  
  - Customer Loyalty Trends  



###  Tools & Skills
- **Microsoft Azure**  
- **Azure SQL Database**  
- **Azure Data Factory**  
- **Azure Data Lake**  
- **Power BI Integration**


  ### Relational Data and Non Relational Data in Azure
![Relational Data](Images/Relational%20Data%20in%20Azure.jpg)
![Non Relational Data](Images/Non%20Relational%20Data%20in%20Azure.jpg)

By the end of Week 5, I was able to design and implement an end-to-end cloud data workflow — from data ingestion and transformation to visualization and insight delivery using Microsoft Azure.

---

##  Week 6 – Python for Data Analysis (pandas, NumPy, Matplotlib, Seaborn)

###  Overview
This week focused on using **Python programming** for performing data analysis — from cleaning and transformation to visualization.  
The goal was to automate data workflows and gain deeper analytical insights using Python’s core data libraries.



###  Key Learnings
- Explored **Python fundamentals** such as variables, loops, functions, and data structures  
- Used **pandas** to:
  - Import and clean datasets (handle missing values, duplicates, and inconsistent data)
  - Filter, sort, and group data for analysis  
  - Merge and join multiple datasets efficiently  
- Applied **NumPy** for:
  - Performing mathematical operations and statistical computations  
  - Working with large numerical arrays for faster processing  
- Utilized **Matplotlib** and **Seaborn** for:
  - Creating data visualizations (bar charts, histograms, scatter plots, heatmaps)  
  - Highlighting trends, correlations, and outliers  
- Wrote Python scripts to **automate repetitive data tasks**, improving efficiency and consistency  



###  Practical Exercise
- Imported a real-world dataset (e.g., GDP per Capita Analysis) using pandas  
- Cleaned the dataset by removing missing values and formatting columns  
- Calculated summary statistics (mean, median, correlations) using NumPy  
- Visualized results using **Matplotlib** and **Seaborn** — including:
  - showing income differences and economic distribution.
  - Scatter plot to explore performance  
  - Correlation between IMF Estimate and WorldBank Estimate 



###  Tools & Skills
- **Python**  
- **pandas** – Data cleaning and manipulation  
- **NumPy** – Numerical and statistical analysis  
- **Matplotlib** – Basic data visualization  
- **Seaborn** – Advanced, aesthetic visualization  
- **Jupyter Notebook**

###  Pandas,Matplotlib and Seaborn
![Pandas](Images/Students%20Mark%20Distribution.jpg)
![Matplotlib and Seaborn](Images/Heat%20map%20using%20Matplotlib%20and%20Seaborn.jpg)

 *
By the end of Week 6, I was able to clean, analyze, and visualize complex datasets programmatically using Python, automating manual workflows.


## About Me
I’m a data enthusiast passionate about turning raw data into actionable insights.  
This bootcamp helped me strengthen my technical foundation and real-world problem-solving skills in data analytics.




